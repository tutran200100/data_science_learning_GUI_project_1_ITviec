{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1m4kiZv2WYGldLIZemle-eD_JwliwFe4M","authorship_tag":"ABX9TyNBfiM3glHrU1SmvEP2LP2W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install streamlit\n","!pip install pyngrok\n","!pip install deep_translator\n","!pip install langdetect\n","!pip install underthesea\n","!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"fz34jP5B91Jm","executionInfo":{"status":"ok","timestamp":1750950573878,"user_tz":-420,"elapsed":48305,"user":{"displayName":"Tú Trần","userId":"10158291830435953037"}},"outputId":"8c68c343-bd06-4161-cedc-561df70f2531"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.0)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.4)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.6.15)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n","Requirement already satisfied: underthesea in /usr/local/lib/python3.11/dist-packages (6.8.4)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.2.1)\n","Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.11/dist-packages (from underthesea) (0.9.11)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.6.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\n","Requirement already satisfied: underthesea-core==1.0.4 in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.0.4)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.6.15)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/Hoc_tap/Data_Science/7._Do_an_tot_nghiep/GUI_project_1/project_1_app.py\n","import streamlit as st\n","\n","# ----- NHẬP THƯ VIỆN VÀ FILE HỖ TRỢ CẦN THIẾT -----\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","\n","# For EDA and Text Preprocessing\n","from wordcloud import WordCloud, STOPWORDS\n","import string\n","import os\n","import re\n","from deep_translator import GoogleTranslator\n","from langdetect import detect\n","from underthesea import word_tokenize, pos_tag, sent_tokenize\n","import emoji\n","\n","# For Sentiment Analyst\n","from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","from nltk.probability import FreqDist\n","from sklearn.utils import resample\n","\n","# For Text Clustering\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n","from sklearn.decomposition import LatentDirichletAllocation, PCA\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.cluster import DBSCAN\n","from sklearn.mixture import GaussianMixture\n","\n","import joblib\n","from joblib import dump\n","from joblib import load\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# ----- TIỀN XỬ LÝ VĂN BẢN CHO SENTIMENT ANALYSIS -----\n","def preprocess_review_text(df, col_like, col_suggestion):\n","    # Load emojicon\n","    with open('emojicon.txt', 'r', encoding=\"utf8\") as file:\n","        emoji_dict = {line.split('\\t')[0]: line.split('\\t')[1] for line in file.read().split('\\n') if '\\t' in line}\n","\n","    # Load teencode\n","    with open('teencode.txt', 'r', encoding=\"utf8\") as file:\n","        teen_dict = {line.split('\\t')[0]: line.split('\\t')[1] for line in file.read().split('\\n') if '\\t' in line}\n","\n","    # Load English to Vietnamese dictionary\n","    with open('english-vnmese.txt', 'r', encoding=\"utf8\") as file:\n","        english_dict = {line.split('\\t')[0]: line.split('\\t')[1] for line in file.read().split('\\n') if '\\t' in line}\n","\n","    # Load wrong word list\n","    with open('wrong-word-2.txt', 'r', encoding=\"utf8\") as file:\n","        wrong_lst = file.read().split('\\n')\n","\n","    # Load stopwords\n","    with open('vietnamese-stopwords.txt', 'r', encoding=\"utf8\") as file:\n","        stopwords_lst = file.read().split('\\n')\n","\n","    def smart_translate_langdetect(text):\n","        try:\n","            lang = detect(text)\n","            if lang == 'en':\n","                return GoogleTranslator(source='en', target='vi').translate(text)\n","            else:\n","                return text\n","        except:\n","            return text\n","\n","    def process_special_word(text):\n","        special_words = ['không', 'chẳng', 'chả', 'chưa', 'thiếu', 'hơi']\n","        new_text = ''\n","        text_lst = text.split()\n","        i = 0\n","        while i < len(text_lst):\n","            word = text_lst[i]\n","            if word in special_words and i + 1 < len(text_lst):\n","                combined = word + '_' + text_lst[i + 1]\n","                new_text += combined + ' '\n","                i += 2\n","            else:\n","                new_text += word + ' '\n","                i += 1\n","        return new_text.strip()\n","\n","    def loaddicchar():\n","        uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n","        unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n","        dic = {}\n","        char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split('|')\n","        charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split('|')\n","        for i in range(len(char1252)):\n","            dic[char1252[i]] = charutf8[i]\n","        return dic\n","\n","    def covert_unicode(txt):\n","        dicchar = loaddicchar()\n","        return re.sub('|'.join(dicchar.keys()), lambda x: dicchar[x.group()], txt)\n","\n","    def clean_text_SA(text):\n","        text = text.lower()\n","        text = text.replace(\"'\", '')\n","        text = re.sub(r'\\.+', '.', text)\n","        text = re.sub(r'([a-z]+?)\\1+', r'\\1', text)\n","        new_sentence = ''\n","        for sentence in sent_tokenize(text):\n","            sentence = ''.join(emoji_dict.get(word, word) + ' ' if word in emoji_dict else word for word in list(sentence))\n","            sentence = ' '.join(teen_dict.get(word, word) for word in sentence.split())\n","            pattern = r'(?i)\\b[a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ]+\\b'\n","            sentence = ' '.join(re.findall(pattern, sentence))\n","            sentence = sentence.replace('.', '')\n","            lst_word_type = ['A','AB','V','VB','VY','R']\n","            sentence = ' '.join(word[0] if word[1].upper() in lst_word_type else '' for word in pos_tag(process_special_word(word_tokenize(sentence, format=\"text\"))))\n","            new_sentence += sentence + '. '\n","        text = new_sentence\n","        english_dict['environment'] = 'moi_truong'\n","        english_dict['ot'] = 'tang_ca'\n","        text = ' '.join(english_dict.get(word, word) for word in text.split())\n","        stopwords_lst.append('cong_ty')\n","        text = ' '.join(word for word in text.split() if word not in stopwords_lst)\n","        text = ' '.join(word for word in text.split() if word not in wrong_lst)\n","        text = re.sub(r'\\s+', ' ', text)\n","        return text.strip()\n","\n","    # Process translation\n","    df[col_like + '_translated'] = df[col_like].apply(smart_translate_langdetect)\n","    df[col_suggestion + '_translated'] = df[col_suggestion].apply(smart_translate_langdetect)\n","\n","    # Fill NA\n","    df[col_like + '_translated'].fillna('na', inplace=True)\n","    df[col_suggestion + '_translated'].fillna('na', inplace=True)\n","\n","    # Unicode normalization\n","    df[col_like + '_translated'] = df[col_like + '_translated'].apply(covert_unicode)\n","    df[col_suggestion + '_translated'] = df[col_suggestion + '_translated'].apply(covert_unicode)\n","\n","    # Clean text\n","    df['like_cleaned'] = df[col_like + '_translated'].apply(clean_text_SA)\n","    df['suggestion_cleaned'] = df[col_suggestion + '_translated'].apply(clean_text_SA)\n","\n","    # Combine both\n","    df['review_cleaned'] = df['like_cleaned'] + ' ' + df['suggestion_cleaned']\n","\n","    return df[['review_cleaned']]\n","\n","# ----- Load model của Sentiment Analysis -----\n","best_rf_pipeline = joblib.load('rf_tfidf_pipeline_sentiment.joblib')\n","\n","# ---- Load data cho text clustering ------\n","data = pd.read_excel('Reviews.xlsx')\n","data_TC = pd.read_csv('Reviews_cleaned_for_TC_v2.csv')\n","data_topic = data_TC.copy()\n","\n","# ----- Load model của Text Clustering -----\n","pipeline_like = joblib.load('pipeline_like.pkl')\n","# Trích xuất từng bước\n","vectorizer_like = pipeline_like.named_steps['vectorizer']\n","lda_like = pipeline_like.named_steps['lda']\n","kmeans_like = pipeline_like.named_steps['kmeans']\n","# Transform từng bước\n","like_vectorizer = vectorizer_like.transform(data_topic['like_cleaned'])\n","like_topic_dist = lda_like.transform(like_vectorizer)\n","like_cluster = kmeans_like.predict(like_topic_dist)\n","\n","pipeline_suggestion = joblib.load('pipeline_suggestion.pkl')\n","# Trích xuất từng bước\n","vectorizer_suggestion = pipeline_suggestion.named_steps['vectorizer']\n","lda_suggestion = pipeline_suggestion.named_steps['lda']\n","kmeans_suggestion = pipeline_suggestion.named_steps['kmeans']\n","# Transform từng bước\n","suggestion_vectorizer = vectorizer_suggestion.transform(data_topic['suggestion_cleaned'])\n","suggestion_topic_dist = lda_suggestion.transform(suggestion_vectorizer)\n","suggestion_cluster = kmeans_suggestion.predict(suggestion_topic_dist)\n","\n","data_topic['like_topic'] = like_cluster\n","data_topic['suggestion_topic'] = suggestion_cluster\n","\n","# ----- Recommendation Mapping for clustering -----\n","RECOMMEND_TOPIC_MAP = {\n","    0: \"🏢 Cải thiện không gian làm việc và cơ sở vật chất.\\nGợi ý: nâng cấp văn phòng, chỗ ngồi, khu vực nghỉ ngơi, thiết bị.\",\n","\n","    1: \"⚙️ Nâng cấp quy trình & chính sách nội bộ và hoạt động nhóm.\\nGợi ý: đơn giản hóa thủ tục nội bộ, cải tiến hệ thống quản lý, tăng minh bạch.\",\n","\n","    2: \"💸 Cải thiện chế độ tăng ca, lương, thưởng và đãi ngộ.\\nGợi ý: xem xét chế độ tăng ca, điều chỉnh lương, thưởng theo hiệu suất, tăng hỗ trợ tài chính.\"\n","}\n","\n","LIKE_TOPIC_MAP = {\n","    0: \"🏢 Không gian làm việc & Cơ sở vật chất\",\n","    1: \"📈 Cơ hội phát triển & Văn hóa công ty\",\n","    2: \"💰 Phúc lợi & Đãi ngộ & Đồng nghiệp\",\n","}\n","\n","# Tạo DataFrame chỉ chứa ID công ty và suggestion_topic\n","company_suggestions = data_topic[['id', 'like_topic', 'suggestion_topic']]\n","\n","# Sau đó, lấy ra topic có số lần xuất hiện nhiều nhất\n","def get_top_n_suggestions(group, n=2):\n","  if len(group) == 0:\n","    return []\n","  topic_counts = group['suggestion_topic'].value_counts()\n","  # Lấy tối đa n topic có tần suất cao nhất\n","  top_topics_suggestion = topic_counts.head(n).index.tolist()\n","  return top_topics_suggestion\n","\n","def get_top_n_like(group, n=1):\n","  if len(group) == 0:\n","    return []\n","  topic_counts = group['like_topic'].value_counts()\n","  # Lấy tối đa n topic có tần suất cao nhất\n","  top_topics_like = topic_counts.head(n).index.tolist()\n","  return top_topics_like\n","\n","company_top_suggestions = company_suggestions.groupby('id').apply(get_top_n_suggestions).reset_index(name='top_suggestions')\n","company_top_likes = company_suggestions.groupby('id').apply(get_top_n_like).reset_index(name='top_likes')\n","\n","# Chuyển danh sách các topic suggestions sang tên gợi ý dựa vào mapping\n","company_top_likes['top_like_names'] = company_top_likes['top_likes'].apply(\n","    lambda topics: [LIKE_TOPIC_MAP.get(topic, \"Không rõ chủ đề\") for topic in topics]\n",")\n","company_top_suggestions['top_suggestion_names'] = company_top_suggestions['top_suggestions'].apply(\n","    lambda topics: [RECOMMEND_TOPIC_MAP.get(topic, \"Không rõ chủ đề\") for topic in topics]\n",")\n","\n","### ----- Back-up ------\n","# Hàm lấy top n topic cho 1 cột\n","def get_top_n(group, column, n=1):\n","    if group.empty:\n","        return []\n","    return group[column].value_counts().head(n).index.tolist()\n","\n","# Nhóm theo ID rồi lấy top topic cho cả 2 cột trong cùng 1 apply\n","company_top_topics = company_suggestions.groupby('id').apply(\n","    lambda g: pd.Series({\n","        'top_like': get_top_n(g, 'like_topic'),\n","        'top_suggestion': get_top_n(g, 'suggestion_topic')\n","    })\n",").reset_index()\n","\n","# Chuyển danh sách các topic like và suggestions sang tên gợi ý dựa vào mapping\n","company_top_topics['top_like_names'] = company_top_topics['top_like'].apply(\n","    lambda topics: [LIKE_TOPIC_MAP.get(topic, \"Không rõ chủ đề\") for topic in topics]\n",")\n","\n","company_top_topics['top_suggestion_names'] = company_top_topics['top_suggestion'].apply(\n","    lambda topics: [RECOMMEND_TOPIC_MAP.get(topic, \"Không rõ chủ đề\") for topic in topics]\n",")\n","\n","# ----- Streamlit App -----\n","\n","# Thiết lập tiêu đề chính\n","st.set_page_config(page_title=\"Ứng dụng Demo\", layout=\"wide\")\n","\n","# Thanh menu bên trái (sidebar)\n","with st.sidebar:\n","    st.title(\"Menu\")\n","\n","    # Chọn trang mục\n","    page = st.radio(\"Chọn trang\", [\"1. Giới thiệu\", \"2. Phân tích & Kết quả\", \"3. Phân tích cảm xúc\", \"4. Phân nhóm đánh giá\"])\n","\n","    # Dòng phân cách\n","    st.markdown(\"---\")\n","\n","    # Thông tin nhóm\n","    st.markdown(\"**Thành viên nhóm:**\")\n","    st.markdown(\"- Mr. Lê Đức Anh\")\n","    st.markdown(\"- Mr. Trần Anh Tú\")\n","\n","    # Giáo viên hướng dẫn\n","    st.markdown(\"**GVHD:**\")\n","    st.markdown(\"- Ms. Khuất Thùy Phương\")\n","\n","    # Khoảng trống đẩy nội dung xuống\n","    st.markdown(\"<br><br><br><br><br>\", unsafe_allow_html=True)\n","\n","     # Dòng chữ nhỏ ở dưới cùng\n","    st.markdown(\n","        \"<div style='font-size: 11px; color: gray; text-align: center;'>\"\n","        \"Dự án tốt nghiệp<br>Data Science & Machine Learning<br>TTTH - ĐH KHTN\"\n","        \"</div>\",\n","        unsafe_allow_html=True)\n","\n","# Hiển thị nội dung theo từng trang\n","if page == \"1. Giới thiệu\":\n","    # Hiển thị banner ITviec\n","    st.image(\"banner_itviec_3.jpg\", caption='Nguồn: ITviec', use_container_width=True)\n","    st.header(\"1. Giới thiệu\")\n","\n","    # Giới thiệu ITviec\n","    st.subheader(\"Về ITviec\")\n","    st.markdown(\"\"\"\n","    ITViec là nền tảng chuyên cung cấp các cơ hội việc làm trong lĩnh vực Công nghệ Thông tin (IT) hàng đầu Việt Nam.\n","    Nền tảng này được thiết kế để giúp người dùng, đặc biệt là các developer, phát triển sự nghiệp một cách hiệu quả.\n","    Người dùng có thể dễ dàng tìm kiếm việc làm trên ITViec theo nhiều tiêu chí khác nhau như kỹ năng, chức danh và công ty.\n","    Bên cạnh đó, ITViec còn cung cấp nhiều tài nguyên hữu ích hỗ trợ người tìm việc và phát triển bản thân, bao gồm:\n","    \"\"\")\n","    st.markdown(\"\"\"\n","    - **Đánh giá công ty**: Giúp ứng viên có cái nhìn tổng quan về môi trường làm việc và văn hóa của các công ty IT.\n","    - **Blog chuyên ngành**: Chia sẻ các bài viết về kiến thức chuyên môn, kỹ năng mềm, xu hướng công nghệ và các lời khuyên nghề nghiệp hữu ích.\n","    - **Báo cáo lương IT**: Cung cấp thông tin về mức lương trên thị trường, giúp người dùng có cơ sở để đàm phán mức đãi ngộ phù hợp.\n","    \"\"\")\n","\n","    # Giới thiệu Dataset\n","    st.subheader(\"Về bộ dữ liệu\")\n","    st.markdown(\"\"\"\n","    Bộ dữ liệu bao gồm **hơn 8.000 đánh giá** từ các nhân viên và cựu nhân viên trong ngành IT tại Việt Nam, được thu thập từ ITviec.com.\n","\n","    Các trường chính:\n","    - `What I liked`: Những điều tích cực người đánh giá cảm nhận.\n","    - `Suggestions for improvement`: Gợi ý cải thiện dành cho công ty.\n","    - `Company Mame`, `id`, `Recommend?`, `Overall Rating`, v.v...\n","\n","    Dữ liệu đã được xử lý tiếng Việt, chuẩn hóa và làm sạch trước khi áp dụng mô hình học máy.\n","    \"\"\")\n","\n","    # Mục tiêu của ứng dụng\n","    st.subheader(\"Mục tiêu của ứng dụng\")\n","    st.markdown(\"\"\"\n","    Ứng dụng này được xây dựng với hai mục tiêu chính:\n","\n","    1. **Phân tích cảm xúc (Sentiment Analysis)**: Dự đoán cảm xúc của người đánh giá (Good / Neutral / Bad) dựa trên nội dung họ cung cấp.\n","\n","    2. **Phân nhóm nội dung đánh giá (Information Clustering)**: Tự động phân loại và trực quan hóa các đánh giá theo chủ đề, giúp doanh nghiệp hiểu rõ các điểm mạnh và điểm cần cải thiện.\n","    \"\"\")\n","\n","elif page == \"2. Phân tích & Kết quả\":\n","    st.header(\"2. Phân tích và Kết quả Mô hình\")\n","    # 1. Mô tả dữ liệu\n","    st.subheader(\"2.1 Khám phá dữ liệu ban đầu\")\n","    st.markdown(\"- Số lượng dòng dữ liệu: 8417\")\n","    st.markdown(\"- Số lượng cột: 12\")\n","    st.markdown(\"- Trường thông tin: `What I liked`, `Suggestions for improvement`, `Rating`\")\n","    # Hiển thị vài dòng đầu tiên\n","    st.dataframe(data.head())\n","\n","    col1, col2 = st.columns(2)\n","    with col1:\n","      st.markdown(\"#### Làm sạch\")\n","      st.markdown(\"\"\"\n","      - **Drop duplicates**: 5 entries\n","      - **Drop null values**\n","      - **Drop rows where `What I liked` is null**\n","      - **Drop rows where `Suggestion for improvement` is null**\n","      \"\"\")\n","\n","    with col2:\n","      st.markdown(\"#### Tổng quan dữ liệu\")\n","      st.markdown(\"\"\"\n","        - **`What I liked` feature**\n","        - Mean: 237 digits\n","        - Max: 6384 digits\n","        - **`Suggestion for improvement` feature**\n","        - Mean: 138 digits\n","        - Max: 3813 digits\n","        \"\"\")\n","    st.image(\"EDA_length.png\", caption=\"Độ dài kí tự\")\n","\n","    # 2. Tiền xử lý văn bản\n","    st.subheader(\"2.2 Tiền xử lý văn bản\")\n","\n","    st.markdown(\"\"\"\n","    #### 1. Dịch ngôn ngữ\n","    - Phát hiện ngôn ngữ với `langdetect`\n","    - Dịch tiếng Anh sang tiếng Việt bằng `GoogleTranslator`\n","\n","    #### 2. Mã hóa & Chuẩn hóa ký tự\n","    - Mã hóa chuẩn `UTF-8`\n","    - Chuyển toàn bộ văn bản thành chữ **thường**\n","    - Loại bỏ ký tự **lặp lại** (vd: *thiệtttt* → *thiệt*)\n","\n","    #### 3. Xử lý Emoji & Teen Code\n","    - **Sentiment:** Thay emoji bằng từ mô tả (`emojicon.txt`)\n","    - **Clustering:** Phát hiện và xóa emoji\n","    - Chuyển teen code sang từ thông dụng (`teencode.txt`)\n","\n","    #### 4. Làm sạch văn bản\n","    - Loại bỏ **dấu câu** và **chữ số**\n","    - Chuẩn hóa **Unicode** từ các dạng gõ lỗi\n","\n","    #### 5. POS Tag & Từ đặc biệt\n","    - Gắn nhãn từ loại bằng `underthesea.pos_tag`\n","    - Ghép từ đặc biệt: *không, chưa, chả...* → *không_tốt*, *chưa_ổn*\n","\n","    #### 6. Lọc từ theo mục tiêu\n","    - **Sentiment:** giữ từ loại `['A','AB','V','VB','VY','R']`\n","    - **Clustering:** giữ thêm danh từ `['N', 'Np', 'A', 'AB', 'V', 'VB', 'VY', 'R]`\n","\n","    #### 7. Dịch từ đơn\n","    - Dùng `english-vnmese.txt` để dịch các từ đơn còn sót\n","\n","    #### 8. Loại bỏ nhiễu\n","    - Xoá stopwords (`vietnamese-stopwords.txt`)\n","    - Xoá từ sai (`wrong-word-2.txt`)\n","    - Xoá khoảng trắng thừa\n","    \"\"\")\n","\n","    st.markdown(\"### Word Cloud của tệp data cho Sentiment Analysis\")\n","    col3, col4 = st.columns(2)\n","    with col3:\n","        st.image(\"word_cloud_like_sentiment.png\", caption=\"WordCloud - What I liked\") #use_container_width=True\n","    with col4:\n","        st.image(\"word_cloud_suggestion_sentiment.png\", caption=\"WordCloud - Suggestions for improvement\") #use_container_width=True\n","\n","\n","    st.markdown(\"### Word Cloud của tệp data cho Information Clustering\")\n","    col5, col6 = st.columns(2)\n","    with col5:\n","        st.image(\"word_cloud_like_cluster.png\", caption=\"WordCloud - What I liked\") #use_container_width=True\n","    with col6:\n","        st.image(\"word_cloud_suggestion_cluster.png\", caption=\"WordCloud - Suggestions for improvement\") #use_container_width=True\n","\n","    # 3. Trích xuất đặc trưng và mô hình hóa\n","    st.subheader(\"2.3 Mô hình phân tích cảm xúc\")\n","    st.markdown(\"- Sử dụng mô hình **Random Forest** với đầu vào là TF-IDF vector\")\n","    st.markdown(\"- Độ chính xác: **97.77%**\")\n","    # Hiển thị hình ảnh kết quả các model\n","    st.image(\"sentiment_analysis_results.png\", caption=\"Model Comparison\")\n","    # Hiển thị biểu đồ confusion matrix nếu có\n","    st.image(\"confusion_matrix_sentiment_RF.png\", caption=\"Confusion Matrix Random Forest\")\n","\n","    # 4. Phân tích chủ đề bằng LDA và K Means\n","    st.subheader(\"2.4 Phân tích chủ đề\")\n","    st.markdown(\"- Sử dụng **LDA + KMeans** để phân nhóm theo chủ đề review\")\n","    st.markdown(\"- Số lượng chủ đề (LDA) và cụm (KMeans) đều là 3 cho mỗi phần `What I liked` và `Suggestion`\")\n","\n","    # Hiển thị hình ảnh biểu đồ tam giác\n","    st.markdown(\"- Silhoutte Score - What I liked: **0.59**\")\n","    st.image(\"ternary_like.png\", caption=\"Biểu đồ phân bổ - LIKE\")\n","    st.markdown(\"- Silhoutte Score - What I liked: **0.64**\")\n","    st.image(\"ternary_suggestion.png\", caption=\"Biểu đồ phẩn bổ - SUGGESTION\")\n","\n","    # Kết quả cluster - LIKE\n","    st.markdown(\"### **Kết quả cluster 'What I liked'**\")\n","    col7, col8, col9 = st.columns(3)\n","    # Hiển thị ảnh trong từng cột\n","    with col7:\n","        st.image(\"topic_0_like.png\", caption=\"Top 10 keywords - chủ đề 0\") # use_container_width=True\n","\n","    with col8:\n","        st.image(\"topic_1_like.png\", caption=\"Top 10 keywords - chủ đề 1\") # use_container_width=True\n","\n","    with col9:\n","        st.image(\"topic_2_like.png\", caption=\"Top 10 keywords - chủ đề 2\") # use_container_width=True\n","\n","    # Cluster 0\n","    st.markdown(\"#### 🏢 Cluster 0: Không gian làm việc & Cơ sở vật chất (chủ đề 1)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `văn_phòng`, `đẹp`, `đội`, `phòng`, `máy`\n","    \"\"\")\n","\n","    # Cluster 1\n","    st.markdown(\"#### 📈 Cluster 1: Cơ hội phát triển & Văn hóa công ty (chủ đề 2)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `phát_triển`, `chính_sách`, `văn_hóa`\n","    \"\"\")\n","\n","    # Cluster 2\n","    st.markdown(\"#### 💰 Cluster 2: Phúc lợi, Đãi ngộ & Đồng nghiệp (chủ đề 0)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `lương`, `tăng_ca`, `chế_độ`, `dự_án`, `sếp`, `đồng_nghiệp`\n","    \"\"\")\n","\n","    # Kết quả cluster - SUGGESTION\n","    st.markdown(\"### **Kết quả cluster 'Suggestions to improve'**\")\n","    col10, col11, col12 = st.columns(3)\n","    # Hiển thị ảnh trong từng cột\n","    with col10:\n","        st.image(\"topic_0_suggestion.png\", caption=\"Top 10 keywords - chủ đề 0\") # use_container_width=True\n","\n","    with col11:\n","        st.image(\"topic_1_suggestion.png\", caption=\"Top 10 keywords - chủ đề 1\") # use_container_width=True\n","\n","    with col12:\n","        st.image(\"topic_2_suggestion.png\", caption=\"Top 10 keywords - chủ đề 2\") # use_container_width=True\n","\n","    # Cluster 0\n","    st.markdown(\"#### 🏢 Cluster 0: Cải thiện không gian & cở sở vật chất (chủ đề 0)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `văn_phòng`, `phòng`, `chỗ`, `đội`, `trưa`, `hoạt_động`\n","    \"\"\")\n","\n","    # Cluster 1\n","    st.markdown(\"#### ⚙️ Cluster 1: Nâng cấp quy trình & chính sách nội bộ và hoạt động nhóm (chủ đề 1)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `cải_thiện`, `đội`, `chính_sách`, `phát_triển`, `dự án`, `cải_thiện`\n","    \"\"\")\n","\n","    # Cluster 2\n","    st.markdown(\"#### 💸 Cluster 2: Tăng ca, lương, thưởng & đãi ngộ (chủ đề 2)\")\n","    st.markdown(\"\"\"\n","    **Từ khóa tiêu biểu:** `tăng_ca`, `lương`, `tiền`, `thưởng`, `sếp`, `chậm`\n","    \"\"\")\n","\n","# Sentiment Analysis\n","elif page == \"3. Phân tích cảm xúc\":\n","    st.header(\"3. Phân tích cảm xúc\")\n","    st.write(\"Nhập tay hoặc tải file lên để dự đoán\")\n","\n","    # --- Nhóm 1: Nhập tay ---\n","    st.subheader(\"Nhập tay đánh giá\")\n","    liked_input = st.text_area(\"What I liked\")\n","    suggestion_input = st.text_area(\"Suggestions for improvement\")\n","\n","    if st.button(\"Dự đoán\",  key=\"predict_manual\"):\n","        if liked_input.strip() == \"\" and suggestion_input.strip() == \"\":\n","            st.warning(\"Vui lòng nhập ít nhất một trường.\")\n","        else:\n","            try:\n","                df_input = pd.DataFrame({\n","                    \"What I liked\": [liked_input],\n","                    \"Suggestions for improvement\": [suggestion_input]\n","                })\n","                df_input = preprocess_review_text(df_input, \"What I liked\", \"Suggestions for improvement\")\n","                preds = best_rf_pipeline.predict(df_input['review_cleaned'])\n","\n","                label_mapping = {0: 'Bad', 1: 'Neutral', 2: 'Good'}\n","                pred_label = label_mapping.get(preds[0], \"Unknown\")\n","\n","                st.success(f\"Sentiment dự đoán: **{pred_label}**\")\n","            except Exception as e:\n","                st.error(f\"Lỗi xảy ra: {e}\")\n","\n","    st.markdown(\"---\")\n","\n","    # --- Nhóm 2: Upload file ---\n","    st.subheader(\"Upload file Excel (.xlsx) hoặc CSV (.csv)\")\n","    uploaded_file = st.file_uploader(\"Chọn file Excel hoặc CSV chứa 2 cột: 'What I liked' và 'Suggestions for improvement'\", type=['xlsx', 'csv'])\n","\n","    if uploaded_file is not None:\n","        try:\n","            if uploaded_file.name.endswith('.xlsx'):\n","                df_upload = pd.read_excel(uploaded_file)\n","            else:\n","                df_upload = pd.read_csv(uploaded_file)\n","\n","            # Kiểm tra cột cần thiết\n","            required_cols = ['What I liked', 'Suggestions for improvement']\n","            if all(col in df_upload.columns for col in required_cols):\n","                if st.button(\"Dự đoán\", key=\"predict_from_file\"):\n","                    df_cleaned = preprocess_review_text(df_upload, \"What I liked\", \"Suggestions for improvement\")\n","                    preds = best_rf_pipeline.predict(df_cleaned['review_cleaned'])\n","\n","                    label_mapping = {0: 'Bad', 1: 'Neutral', 2: 'Good'}\n","                    df_upload['Predicted Sentiment'] = [label_mapping.get(p, \"Unknown\") for p in preds]\n","\n","                    st.success(\"Dự đoán hoàn tất! Kết quả hiển thị bên dưới:\")\n","                    st.dataframe(df_upload[['What I liked', 'Suggestions for improvement', 'Predicted Sentiment']])\n","\n","                    # Tạo và tải file kết quả\n","                    output_csv = df_upload[['What I liked', 'Suggestions for improvement', 'Predicted Sentiment']].to_csv(index=False).encode('utf-8-sig')\n","                    st.download_button(\"Tải xuống file kết quả\", data=output_csv, file_name='sentiment_analysis_results.csv', mime='text/csv')\n","            else:\n","                st.error(f\"File thiếu cột: {required_cols}\")\n","        except Exception as e:\n","            st.error(f\"Lỗi khi xử lý file: {e}\")\n","\n","\n","elif page == \"4. Phân nhóm đánh giá\":\n","    st.header(\"4. Phân nhóm đánh giá\")\n","    # st.write(\"Lựa chọn công ty cần tìm hiểu\")\n","\n","    # Tạo danh sách dropdown \"ID - Tên công ty\"\n","    company_options = data_topic[['id', 'Company Name']].drop_duplicates()\n","    company_options['display_name'] = company_options['id'].astype(str) + \" - \" + company_options['Company Name']\n","\n","    selected_display = st.selectbox(\"Chọn công ty\", company_options['display_name'].tolist())\n","\n","    if selected_display:\n","        # Trích xuất ID công ty từ chuỗi chọn\n","        company_id_input = int(selected_display.split(\" - \")[0])\n","\n","        try:\n","            # --- LIKE TRIANGLE ---\n","            df_like = pd.DataFrame(like_topic_dist, columns=[\"Topic 0\", \"Topic 1\", \"Topic 2\"])\n","            df_like = pd.concat([df_like, data_topic['id']], axis=1)\n","            df_like = df_like[df_like['id'] == company_id_input]\n","            df_like[\"Cluster\"] = data_topic['like_topic'].astype(str)\n","\n","            st.subheader(\"Đánh giá phân loại công ty\")\n","            fig_like = px.scatter_ternary(\n","                df_like,\n","                a=\"Topic 0\", b=\"Topic 1\", c=\"Topic 2\",\n","                color=\"Cluster\",\n","                size_max=10,\n","                opacity=0.8,\n","                title=\"Biểu đồ phân bổ đánh giá 'What I liked'\",\n","                labels={\n","                    \"Topic 0\": \"Phúc lợi & Đãi ngộ & Đồng nghiệp\",\n","                    \"Topic 1\": \"Không gian làm việc & Cơ sở vật chất\",\n","                    \"Topic 2\": \"Cơ hội phát triển & Văn hóa công ty\",\n","                    \"Cluster\": \"Cụm\"\n","                }\n","            )\n","            st.plotly_chart(fig_like)\n","\n","            # --- SUGGESTION TRIANGLE ---\n","            df_suggestion = pd.DataFrame(suggestion_topic_dist, columns=[\"Topic 0\", \"Topic 1\", \"Topic 2\"])\n","            df_suggestion = pd.concat([df_suggestion, data_topic['id']], axis=1)\n","            df_suggestion = df_suggestion[df_suggestion['id'] == company_id_input]\n","            df_suggestion[\"Cluster\"] = data_topic['suggestion_topic'].astype(str)\n","\n","            # st.subheader(\"Đánh giá phân loại công ty\")\n","            fig_sugg = px.scatter_ternary(\n","                df_suggestion,\n","                a=\"Topic 0\", b=\"Topic 1\", c=\"Topic 2\",\n","                color=\"Cluster\",\n","                size_max=10,\n","                opacity=0.8,\n","                title=\"Biểu đồ phân bổ đánh giá 'Suggestions for improvement'\",\n","                labels={\n","                    \"Topic 0\": \"Cải thiện không gian & cơ sở vật chất\",\n","                    \"Topic 1\": \"Quy trình, chính sách & teamwork\",\n","                    \"Topic 2\": \"Tăng ca, lương, thưởng & đãi ngộ\",\n","                    \"Cluster\": \"Cụm\"\n","                }\n","            )\n","            st.plotly_chart(fig_sugg)\n","\n","            # --- GỢI Ý CẢI THIỆN ---\n","            st.subheader(\"Top ưu điểm của công ty\")\n","            row_like = company_top_likes[company_top_likes['id'] == company_id_input]\n","            row_suggestion = company_top_suggestions[company_top_suggestions['id'] == company_id_input]\n","\n","            if not row_like.empty:\n","                for like in row_like['top_like_names'].iloc[0]:\n","                    st.markdown(f\"**{like}**\")\n","            else:\n","                st.warning(\"Không tìm thấy thông tin ưu điểm cho công ty này.\")\n","\n","            st.subheader(\"Top đề xuất cải thiện\")\n","            if not row_suggestion.empty:\n","                for suggestion in row_suggestion['top_suggestion_names'].iloc[0]:\n","                    st.markdown(f\"**{suggestion}**\")\n","            else:\n","                st.warning(\"Không tìm thấy thông tin đề xuất cho công ty này.\")\n","\n","        except Exception as e:\n","            st.error(f\"Có lỗi xảy ra: {e}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Syi6Q-jknXwL","executionInfo":{"status":"ok","timestamp":1750950574096,"user_tz":-420,"elapsed":215,"user":{"displayName":"Tú Trần","userId":"10158291830435953037"}},"outputId":"09700f16-bfd7-4ab4-cab0-dc91765f4273"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/Hoc_tap/Data_Science/7._Do_an_tot_nghiep/GUI_project_1/project_1_app.py\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Hoc_tap/Data_Science/7._Do_an_tot_nghiep/GUI_project_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlkNuGu6FRJ2","executionInfo":{"status":"ok","timestamp":1750950574107,"user_tz":-420,"elapsed":8,"user":{"displayName":"Tú Trần","userId":"10158291830435953037"}},"outputId":"053e2b72-f9a6-4961-c2d5-7c613420cfe9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Hoc_tap/Data_Science/7._Do_an_tot_nghiep/GUI_project_1\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","import threading\n","\n","ngrok.set_auth_token('2ywMgs25RHcQ6kXPwb4aBivyJfm_3LE4tutg6aUFhV6Y2WzmJ')\n","\n","# Khởi tạo cổng cho Streamlit\n","port = 8501\n","public_url = ngrok.connect(port)\n","print(f'Ngrok URL: {public_url}')\n","\n","# Chạy Streamlit trong thread phụ\n","def run():\n","    !streamlit run project_1_app.py --server.port {port} --server.enableCORS false\n","\n","thread = threading.Thread(target=run)\n","thread.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnCuIER2C0aI","executionInfo":{"status":"ok","timestamp":1750950574475,"user_tz":-420,"elapsed":367,"user":{"displayName":"Tú Trần","userId":"10158291830435953037"}},"outputId":"a2adde76-aa46-40fa-f29c-116c5774676f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ngrok URL: NgrokTunnel: \"https://6aa4-34-106-94-203.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]}]}